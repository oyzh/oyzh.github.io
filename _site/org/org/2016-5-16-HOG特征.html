<!DOCTYPE html>
<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.7.0/styles/default.min.css">
	<link rel="stylesheet" type="text/css" href="/styles/post.css">
    <script src="/scripts/jquery-3.1.1.js" type="text/javascript"></script>
	<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    <script type="text/javascript">

    </script>
	<title>HOG特征原理</title>
  </head>

  <body>
    <header>
      <nav>
		<div id="mytitle">
    	<a href="/index.html"><img src="/images/racket.png" height="50" width="50" alt="" /></a>
		<a href="/index.html">Zhenhuan Ouyang's Blog</a>
		</div>
		<a href="https://github.com/oyzh/oyzh.github.io"><img id="forkme" src="/images/fork_me.png"" alt="Fork me on GitHub"></a>
      </nav>
     </header>
	<article>
	<h1 id="articlename">HOG特征原理</h1>
		<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> 原理</h2>
<div class="outline-text-2" id="text-1">
<p>
局部对象的appearance和shape可以通过局部梯度强度或边缘方向来描述，即使不知道相应的梯度或边缘位置的精确知识。
</p>
</div>
</div>
<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2"><span class="section-number-2">2</span> 实现</h2>
<div class="outline-text-2" id="text-2">
<p>
RGB colour space with no gamma correction; [−1, 0, 1] gradient filter with no smoothing; linear gradient voting into 9 orientation bins in 0◦–180◦; 16×16 pixel blocks of four 8×8 pixel cells; Gaussian spatial window with σ = 8 pixel; L2-Hys (Lowe-style clipped L2 norm) block normalization; block spacing stride of 8 pixels (hence 4-fold coverage of each cell); 64×128 detection window; linear SVM classifier.
</p>
</div>
</div>
<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3"><span class="section-number-2">3</span> 理解</h2>
<div class="outline-text-2" id="text-3">
<ol class="org-ol">
<li>HOG特征是一张图片生成一个特征向量，而不像SIFT是一个特征点生成一个特征向量。因此训练图片需要是一样大，比如论文中的64×128。这样生成的向量才一样长。在准备训练数据时，需要先将行人的框出来，再将图片resize成一样大小。
</li>
<li>在对一张图片进行行人检测时，由于不知道行人的大小，所以需要大小改变的滑动窗口来检测，每一张截取出来的图片需要resize成64×128（或者根据训练是的大小改变），以生成和训练时一样长的向量。
</li>
<li>用训练得到的分类器来分类新的向量。
</li>
<li>对图片的全局的描述是有效的需要一个前提就是图片中物体是突出的，或者说是主体，这样得到的向量才有意义，因此才会使用手工来截取行人的图片。
</li>
</ol>
</div>
</div>


<!-- UY BEGIN -->
<div id="uyan_frame"></div>
<script type="text/javascript" src="http://v2.uyan.cc/code/uyan.js"></script>
<!-- UY END -->


	</article>


	<footer>
	Copyright &#x000A9;&nbsp;2016 &#x000B7 <a href="index.html">oyzh</a>
	</footer>
  </body>
	<script>$("pre").wrapInner("<code></code>");</script>
	<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.7.0/highlight.min.js"></script>
	<script>
		hljs.initHighlightingOnLoad();
	</script>
</html>
