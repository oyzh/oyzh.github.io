<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<title>Deep learning 论文翻译</title>
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="generator" content="Org-mode" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center; }
  .todo   { font-family: monospace; color: red; }
  .done   { color: green; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  pre.src-sh:before    { content: 'sh'; }
  pre.src-bash:before  { content: 'sh'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-R:before     { content: 'R'; }
  pre.src-perl:before  { content: 'Perl'; }
  pre.src-java:before  { content: 'Java'; }
  pre.src-sql:before   { content: 'SQL'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.right  { text-align: center;  }
  th.left   { text-align: center;   }
  th.center { text-align: center; }
  td.right  { text-align: right;  }
  td.left   { text-align: left;   }
  td.center { text-align: center; }
  dt { font-weight: bold; }
  .footpara:nth-child(2) { display: inline; }
  .footpara { display: block; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="/css/style.css">
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2013 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<h1 class="title">Deep learning 论文翻译</h1>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({ TeX: { equationNumbers: {autoNumber: "AMS"} } });
</script>
<hr  />
<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1">监督学习</h2>
<div class="outline-text-2" id="text-1">
<p>
不论是不是有深度的，最一般的机器学习的形式都是监督学习。假设我们想要构建一个系统能根据内容对图片进行分类，比如房子、车子、人或宠物。我们首先搜集一个大的房子、车、人和宠物的数据集，每一张照片被标记了它的类别。在训练期间，机器被输入一张图片并参生一个向量形式的得分输出，每个分数代表一个种类。我们想要需要的种类要在所有种类中得分最高，但在训练前是不太可能。我们计算一个目标函数来测量输出得分与需要的模式的得分之间的错误（或距离）。然后机器可以修改它内部的可调节参数(adjustable parameters)来降低这个错误。这些可调节参数通常被称为权重(weights），它们是可以被看作旋钮(knob)的来定义机器输入-输出函数的实数。在一个典型的深度学习系统中，可能有上百万的这样的可调节权重和数百万的已标记的例子来训练机器。
</p>

<p>
为了更好的调节权重向量，学习算法计算一个梯度向量(gradient vector) for each weight, indicates by what amount the error would increase or decrease if the weight were increased by atiny amount. The weight vector is then adjusted in the opposite direction to the gradient vector.
</p>

<p>
使用所有训练样例平均过后的目标函数可以被看作是权重值的高维向量的一个陡峭的分割面。负梯度向量指出了在这个分割面中最快下降的方向，使它靠近最小值，输出值的错误平均小来最小。
</p>

<p>
实际操作中，从业人员使用一种被称为随机梯度下降(SGD)的步骤。这个步骤包括输入几个例子的输入向量，计算输出和错误，计算这些例子的平均梯度和相应的调整权重。这个过程在许多来自训练集的例子集上重复知道目标函数的平均值停止下降。被称为随机是因为每一个小的例子集给出一个对所有例子的平均梯度的噪音估计。这个简单的处理方式通常能令人吃惊快的找到一个好的权重集合。训练以后，系统的性能在另一个称为测试集的的集合上测试。这种方法能测试机器的“泛化”能力（generalization ability），即对于一个没有在训练集中的新的输入产生好的答案的能力。
</p>

<p>
许多目前机器学习的实际应用是在手工生成的特征上使用线性分类器。一个二分类的线性分类器计算一个特征向量的分量的加权和。如果加权和在一个阈值之上，那么一个输入就被划分到属于某一个特定的类。
</p>

<p>
从1960年代我们已经知道线性分类器仅仅能将输入空间分割成简单的区域，即被一个超平面分开的半空间(half-spaces)。但是像图片和语音识别问题需要输入-输出函数对不输入的不相关不敏感，比如对象的位置、方向或光照变化，或者声音的音高和声调的变化。同时要对特定的微小变化敏感（例如一只白色的狼和一个饲养的像狼一样的白色Samoyed犬）。在像素级别，处于不同环境的两只有不同姿势的Samoyeds图片会非常不同。然而同样背景同样姿势的一只Samoyed和狼的两张照片可能会非常像。一个在原生像素上操作的线性分类器，或其他任何“浅层”（shallow）分类器都不可能区分后一种情况的两幅图，仅仅是将前两张图划分为一个类。这就是为什么浅层分类器需要一个好的特征提取器（feature extractor）来解决可选择-不变性（selectivity-invariance）难题，这个特征产生一种对图像某一方面的表示，这种表示对图像区分很重要，但是对不想关方面变化不产生变化，比如动物姿势变化。为了使分类器更强大，可以使用一般非线性特征（generic non-liner features），比如核方法(kernel methods），但是一般化的特征比如采用高斯核升维的特征不能使学习者对离训练数据很远的数据泛化的很好。传统的选择是手工设计好的特征提取器，这需要强大的工程技术和领域经验。但是如果好的特征能够使用一个通用目地（general-purpose）学习步骤来自动的学习，那么手工设计的步骤就可以避免。这是深度学习的主要优势。
</p>

<p>
一个深度学习的体系结构是一个由简单组件构成的多层堆，它们中所有（或大多数）是为了用来学习，并且大多数是计算非线性的输入输出映射。这个堆中的每一个组件变化它的输入来增加整体的可选择性和表示的不变性。使用多个非线性层，也就是5到20的深度的系统能对输入实现极端复杂的函数，这些输入同时具有对微小的细节敏感——从白色狼中区分Samoyeds——和对大的部相关变化不敏感，例如背景，姿势，光照和周围物体。
</p>
</div>
</div>

<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2">反向传播(Backpropagation)训练多层结构</h2>
<div class="outline-text-2" id="text-2">
<p>
模式识别的早期，研究人员的目标是使用可训练的多层神经网络来代替手工生成的特征，但是尽管它很简单，知道1980年代中期结果也没有被很好理解。正像显示的一样，多层结构可以使用简单的随机梯度下降来训练。只要这些组件对于它们的输入和内部权重是相对平滑的函数，就可以使用反响传播操作来计算梯度。这个方法可以使用并工作的很好的观点是从1970-1980年间不同的群体独立完成的。
</p>

<p>
通过CIFAR研究员的努力，2006人们重新对前馈神经网络产生了兴趣。这些研究员推出了一种无监督的学习过程，这个过程在不要求标定数据的情况下可以创建具有层次化的特征提取器。每一层特征提取器的学习目标是可以重建或建模下面一层的特征提取器的活动(activities)(或者原输入)。By ‘pre-training’ several layers of progressively more complexfeature detectors using this reconstruction objective, the weights of adeep network could be initialized to sensible values.最后一层的输出单元被放在网络的最上层，整个深度系统可以使用标准反向传播来的到很好的调节。这对于识别手写字和行人检测有非常好的效果，特别是当标记的数据非常有限时。
</p>

<p>
‘pre-training’的第一个主要的应用是在语音识别，当适合编程的快速的GPUs来临时，这种应用程序变得可能了，GPUs可以使研究人员训练网络时提高10到20倍的速度。在2009年，这种方法使用在了映射从声音中抽取的参数的短的时间窗口到许多可能代表窗口中间的帧的声音片段。在一个使用少量词汇的标准语音识别基准测试中它打破了记录，同时在大量词汇的任务中也很快打破了记录。2012年，从2009年以来许多主要的语音小组发展了深度网络，并已经部署到了安卓手机上。对于晓得数据集，无监督的‘pre-traning’可以帮组避免过拟合，当标定的例子很少时可以得到很好的泛化能力，或者在我们有很多‘源’任务的例子但很少‘目标’任务的变换设置下。一旦深度学习已形成，那么‘pre-training’被证明仅仅只需要少量的数据集。
</p>

<p>
这里有一种特殊类型的深度回馈网络，它可以比相邻层全部连接的神经网络训练更简单，并更加泛化。这就是卷积神经网络（ConvNet）。在神经网络失去吸引力之后卷积神经网络取得了巨大的成功，目前被计算机视觉领域广泛的使用。
</p>
</div>
</div>

<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3">卷积神经网络</h2>
<div class="outline-text-2" id="text-3">
<p>
卷积神经网络是被设计来处理来自多维数组的数据，比如表示三个颜色通道强度的三个二维数组的彩色图片。许多数据可以表示成多维数组的形式：信号和序列是一维的，包括语言;图像和声谱是二维的;视频和立体图(volumetric imagas)是三维的。在卷积神经网络背后有四个从自然信号中得到的关键点：局部连接（local connections）、shared weight、pooling和多层的使用。
</p>
<hr  />
<a href="http://oyzh.github.io">Back to Homepage</a>
<br>
<a href="http://github.com/oyzh">Github</a>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="validation"></p>
</div>
</body>
</html>
