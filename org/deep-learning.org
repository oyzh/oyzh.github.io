#+HTML_MATHJAX: align:"left" mathml:t path:"http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="/css/style.css">
#+OPTIONS: author:nil
#+OPTIONS: creator:nil
#+OPTIONS: timestamp:nil
-----
#+TITLE:Deep Learning
#+OPTIONS: toc:nil
这是Ian Goodfellow,Aaron Courville和Youshua Bengio在2015出版的书。由于比较新，所以我准备利用这本书结合论文来学习。学习的同时做好笔记。
* 应用数学与机器学习基础
** 线性代数
前面的学过，但是感觉理解的不深入。比如特征向量、特征值的本质，这一部分还需要学习。主要计划是看网上[[http://v.163.com/special/opencourse/daishu.html][线性代数]] 课程。同时也需要看对应的那本书，线性代数是很重要的。
*** 例子：主成份分析（PCA）
假设含有 $m$ 个点的集合 $\{x^{(1)},...,x^{(m)}\}$ 属于 $R^n$ 。现在对这些点做有损压缩。

一种方法：对每一个点 $x^{(i)}\in R^n$ 找到一个对应的向量 $c^{(i)}\in R^l$ 。其中 $l$ 比 $n$ 小。即找到两个函数 $f(x)$ 和 $g(c)$ 。
$$f(x)=c$$
$$x\approx g(f(x))$$
设 $g(c)=Dc$ 。其中 $D$ 是变换矩阵。PCA限制 $D$ 的列向量是相互正交的。并假设每一向量是归一化的。
-----
#+BEGIN_HTML
<a href="http://oyzh.github.io">Back to Homepage</a>
<br>
<a href="http://github.com/oyzh">Github</a>
#+END_HTML
