#+BEGIN_HTML
---
layout: post
title: RBM基础
excerpt: 介绍RBM基础，包括ISING模型和采样
---
#+END_HTML
#+OPTIONS: toc:nil
#+OPTIONS: ^:{}
由于DNN（深度信念网）是由RBM（限制波耳兹曼机）层次连接而成，RBM是一种基于能量的网络模型，这种模型对于有监督和无监督学习都非常有用，而这里面涉及了很多方面的知识，这里记录一下对这些概念的理解和以后需要了解的知识。

关键词：基于能量模型，ISING模型，BM（波尔兹曼机），RBM（限制波尔兹曼机），图模型，概率密度估计，MRC，MCMC，Gibbs sampling。

* 基于能量的函数
对于所有变量的任意组合状态赋予一个值，将这个值成为能量。对比物理中，假设任意一个分子（或者小磁针）正处于某个状态，则此刻所有分子有一个总的能量。这样一个赋值的函数即基于能量的模型。假设X为状态集合，模型参数为W，则能量为 $f(W,X)$ 。可以看到，对于基于能量模型，我们主要要考虑的有：
1. 如何定义能量函数。
2. 如何通过实例学习，包括loss function和learning method。
3. 如何通过学习的模型来解决分类、回归等问题。

* ISING模型
可以毫不夸张地说，Ising模型是统计物理中迄今为止唯一的一个同时具备:表述简单、内涵丰富、应用广泛这三种优点的模型。Ising模型的提出是为了解释铁磁物质的相变，即磁铁在加热到一定临界温度以上会出现磁性消失的现象，而降温到临界温度以下又会表现出磁性。这种有磁性、无磁性两相之间的转变，是一种连续相变（也叫二级相变）。Ising模型假设铁磁物质是由一堆规则排列的小磁针构成，每个磁针只有上下两个方向（自旋）。相邻的小磁针之间通过能量约束发生相互作用，同时又会由于环境热噪声的干扰而发生磁性的随机转变（上变为下或反之）。涨落的大小由关键的温度参数决定，温度越高，随机涨落干扰越强，小磁针越容易发生无序而剧烈地状态转变，从而让上下两个方向的磁性相互抵消，整个系统消失磁性，如果温度很低，则小磁针相对宁静，系统处于能量约束高的状态,大量的小磁针方向一致,铁磁系统展现出磁性。而当系统处于临界温度 $T_C$ 的时候，Ising模型表现出一系列幂律行为和自相似现象。 

参考：http://wiki.swarma.net/index.php/ISING%E6%A8%A1%E5%9E%8B

* BM和RBM
波尔兹曼机是全连接图的一种能量模型，但要学习它的参数 $W$ 非常复杂。因此Hinton提出了RBM，RBM是一个二部图结构的模型，因此可以简化学习。同时可以证明RBM的功能也是非常强大，可以收敛到任意的离散密度函数。它们都有一个隐层，因为可能有一些内在结构没有发现，比如一幅图片的所有像素是vision变量，而图片的类别是隐变量。因此新的能量函数为 $f(W,X,Y)$ 。对于训练，我们利用波尔兹曼分布表示某一状态的概率，对于vision变量求边缘分布，采用最大化似然函数（相当于最小化训练集能量）作为loss function。最后采用梯度下降来训练参数，在估计梯度时要用到Gibbs采样。

RBM是一种MRF，即一种无向图概率模型，具有马尔科夫性质。可以将RBM本质上是概率图模型，只是刚好有其他比较好的性质，比如当可视层和隐层都取值范围是 ${0,1}$ 时，可以将RBM看成一般的前向传播网络，这时 $sigmoid(W_ix+b_i)$ 得到的值就是 $p(H_i = 1|X=x)$ 。一般来说这个概率是通过先算能量，再算概率，但是由于这个模型的良好定义，使得激活值刚好为概率。

* 使用模型
假设输入X，要预测Y，需要得到使能量最小的Y作为标签。当然回归等。而求这样的Y比较麻烦，所以有很多其他方法。

可以把RBM当作生成模型，即RBM本身是描述概率密度，每一个状态定义了一个概率。因此可以采用Gibbs采样来得到这个模型的抽样。

* 采样
在这里一共有两个地方用到采样。一是在训练过程中估计梯度的时候。二是得到模型后，我们知道这个模型是对训练数据的一个概率密度估计，因此如果能将它作为生成模型将会非常有用。这样也可以判断模型生成的数据是否是需要的分布。

* 概率图模型、马尔科夫链和隐马尔科夫模型
这里是自己的目前的一些理解，可能有错误。

MRF或贝叶斯网络都是特殊的概率图模型。概率图中每个节点是一个随机变量，边描述了随机变量之间的依赖关系。经常还有马尔科夫链中的状态转换图，这指的是一个随机变量的取值空间，而转换矩阵指的是前一个取值状态对当前的影响。整个马尔科夫链可以看作是一个概率图，每个节点作为随机变量可以取的值就是状态空间中的值，随机变量之间的依赖关系由状态转移图或状态转移矩阵来描述。比如对于一个连续十次的随机过程，这十次的联合分布可以枚举出来，而每一个确定状态的概率也可以根据概率转换图计算出来。

* MCMC
Monto Carlo采样指的是已知概率密度生成样本。MCMC是利用马尔科夫性质来进行Monto Carlo采样，Gibbs采样是MCMC中的一种。
