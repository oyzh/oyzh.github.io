<!DOCTYPE html>
<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.7.0/styles/default.min.css">
	<link rel="stylesheet" type="text/css" href="/styles/post.css">
    <script src="/scripts/jquery-3.1.1.js" type="text/javascript"></script>
	<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    <script type="text/javascript">

    </script>
	<title>深度学习总结</title>
  </head>

  <body>
    <header>
      <nav>
		<div id="mytitle">
    	          <a href="/index.html"><img src="/images/racket.png" height="50" width="50" alt="" /></a>
                  <a style="font-family:Source Code Pro,Monaco,Courier,Consolas;" href="index.html">(set 'name "oyzh")</a>
		</div>
		<a href="https://github.com/oyzh/oyzh.github.io"><img id="forkme" src="/images/fork_me.png"" alt="Fork me on GitHub"></a>
      </nav>
     </header>
	<article>
	<h1 id="articlename">深度学习总结</h1>
		<ol class="org-ol"><li><a id="sec-1" name="sec-1"></a>感知机<br  /><div class="outline-text-2" id="text-1">
<p>
神经网络
认知机
前向传播算法
RBM
LeNet卷积神经网络
手写字符识别
DBN贪婪训练
AlexNet
VGG
GoogLeNet
深度残差网络
</p>
</div>
</li>

<li><a id="sec-2" name="sec-2"></a>冲量<br  /><div class="outline-text-2" id="text-2">
<p>
对一般的梯度下降的权值更新的修改是增加冲量项：
$$\Delta w_{ji}(n)=\eta \delta_jx_{ji}+\alpha \Delta w_{ji}(n-1)$$
直观上的解释是在使用梯度下降时，当误差函数曲面有一个狭长的山谷时，梯度的方向几乎垂直于长轴，结果是权值在短轴间来回震荡，而在长轴上非常缓慢的移动。动量项有助于平均短轴上的震荡，同时加快在长轴上的移动。
</p>
</div>
</li>

<li><a id="sec-3" name="sec-3"></a>Loss function<br  /><div class="outline-text-2" id="text-3">
<p>
loss function是评价当前系统的效果的度量，通常加一个正则项。我们的目的就是最小化loss function，loss function中包含了所有的参数，因此整个任务就变成了求loss function的梯度。有不同的loss function选择，通常设计loss function有以下几个原则：
</p>
<ol class="org-ol">
<li>loss function始终为正，因此目标是最小化loss function
</li>
<li>loss function容易求导
</li>
<li>越接近正确label，loss function的值越小
</li>
</ol>
<p>
在用sigmoid做最后一层的激活函数，label一般标记为输出向量的某一个为1,其他为0,最常用的loss function是欧式度量：
$$\frac{1}{2} \sum_{i=1}^{N} \parallel (o_i-y_i) \parallel^2$$
其中 \(o_i\) 为网络输出， \(y_i\) 为label对应值，注意都是向量。
</p>

<p>
上面式子的缺点是梯度太小，因此现在一般用交叉熵代替：
$$-\sum_{i=1}^{N}\{y_i\ln{a_i}-(1-y_i)\ln(1-a_i)\}$$
可以通过直观得到解释，也可以根据信息论解释。
</p>

<p>
对于sofmax层，也是希望每一类对应的值尽量大，因此它对应的概率要大，一般用negtive log来表示，首先因为归一化所以每一个值都在0到1,因此log之后的值为负，取负后为正，满足第一条，而是越靠近1,也就是越接近正确值越好，而log越靠近1越小，因此满足2和3,因此可以作为loss function。它的形式是：
$$-\sum_{i=1}^{N}{\log p_i}$$
其中 \(p_i\) 是softmax中的定义：
$$p_i = \frac{e^{s_{y_i}}}{\sum_j e^{s_j}}$$
</p>
</div>
</li></ol>


<!-- LiveRe City install code -->
<div id="lv-container" data-id="city" data-uid="MTAyMC8yNjk2NC8zNTUx">
<script type="text/javascript">
   (function(d, s) {
       var j, e = d.getElementsByTagName(s)[0];

       if (typeof LivereTower === 'function') { return; }

       j = d.createElement(s);
       j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
       j.async = true;

       e.parentNode.insertBefore(j, e);
   })(document, 'script');
</script>
<noscript>Please activate JavaScript for write a comment in LiveRe</noscript>
</div>
<!-- completed City install code -->

	</article>


	<footer>
	Copyright &#x000A9;&nbsp;2016 &#x000B7 <a href="/index.html">oyzh</a>
	</footer>
  </body>
	<script>$("pre").wrapInner("<code></code>");</script>
	<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.7.0/highlight.min.js"></script>
	<script>
		hljs.initHighlightingOnLoad();
	</script>
</html>
