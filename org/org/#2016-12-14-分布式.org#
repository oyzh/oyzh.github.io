#+BEGIN_HTML
---
layout: post
title: 分布式系统学习
excerpt: MIT6.824lab1的一些总结,主要关于分布式系统和MapReduce
---
#+END_HTML
#+OPTIONS: toc:nil
#+OPTIONS: ^:{}

* 分布式介绍
** 分布式
   分布式系统就是多台计算机合作解决问题的系统.很多任务可以用分布式解决,比如归并排序时,子序列的排序可以同时在多台计算机上
   运行,最后再统一结果.但是当我们考虑采用分布式解决问题时,我们面临很多单机上不存在的问题,比如如何分配任务,如何发送任务,
   如何处理宕机等.分布式系统可以统一管理多机和解决这些问题,而我们只用考虑算法如何并行.下面先介绍一些实现分布式系统的基础.

** RPC
   远程进程通信使得开发分布式系统非常方便,RPC是一个通信协议,使得进程的远程调用和本机调用一样方便.比如我们在节点master上要分配任务
   给slave1上的Map,这时master准备好运行slave1.Map需要的参数,然后通过RPC来直接调用这个方法.

** 分布式文件系统
   分布式文件系统是分布式系统的基础,对分布式系统来说,它不用考虑更底层的文件管理,而只用关心任务处理相关的问题.
   GFS[1]是谷歌设计的分布式文件系统.

   分布式文件存储在多个机器上,而一个应用打开,读取或写入分布式文件和我们在本机文件系统上的操作却非常相似,通过分布式文件提供的API,
   我们不用考虑文件存放,多机交流等的细节.在分布式文件系统的实现上,和本机文件系统的区别在于,我们在Linux上通过系统调用(write,read等)
   来和文件系统交互.而对于分布式文件系统来说,
   我们需要把我们的请求(相当与系统调用)发送给一个master节点,master节点记录着文件系统的信息,比如某个文件的存放位置等,
   master节点根据请求和它记录的信息将具体操作信息发回请求节点,请求节点还需要一些操作才能真正得到或写入文件.
   所有这些细节都是分布式文件系统来管理.

   我们在每台计算机运行分布式文件系统,他们都是建立在本机文件系统上的.当需要读取/test/filename.txt时,我们使用分布式系统的
   read /test/filename.txt,这时文件系统通过一系列的通信知道文件具体存放的位置,并将文件返回.有了分布式文件系统,我们
   开发分布式系统和分布式应用更加方便.比如MapReduce的中间结果都需要写入到文件中,我们直接写入到分布式文件系统中,而不用
   考虑具体写入到哪里.

* MapReduce
  MapReduce[2]是一种编程模型,或者说是一种数据的处理方式,这种方式使我们可以完全不用考虑分布式,只需要按照要求写出Map和Reduce
  函数,分布式的操作都由系统来管理.

  假设我们已经编写了Map和Reduce函数,从master节点的角度看,有多个slave节点已经向它'注册',表明它们可以实行计算,并且这些slave节点上
  可以运行Map和Reduce函数,master通过RPC调用slave的Map方法,Map的结果是键值对,Map将这些中间结果保存在分布式文件系统中.master调度
  并等待所有Map结束,然后将这些中间结果merge到一起,然后再通过RPC调用slave的Reduce方法,Reduce的处理结果是字符串,它也将中间结果
  存储在分布式文件系统中.最后master将所有结果综合在一起就是最后的结果.

  如果用MapReduce来编写分布式程序,则只需将问题分解成Map和Reduce的两个阶段.通用接口如下:
#+BEGIN_SRC
map func(file string, contents string) []KeyValue{}
reduce func(key string, values[] string) string{}
#+END_SRC
  Map的输入是文件名称和文件内容,输出是键值对,Reduce的输入是一个键值和对应的值的序列,输出是一个字符串.
  比如如果要对多个文件统计单词出现的个数.Map的实现就是将contents分解成单词,并且单词作为key,value都是1.
  Reduce就是统计一下values的个数.
#+BEGIN_SRC
func mapF(document string, value string) (res []mapreduce.KeyValue) {
        words := strings.FieldsFunc(value,split) // 文本分解成单词数组
        for _, w := range words {
                kv := mapreduce.KeyValue{w,"1"} // 单词作为key,value是"1"
                res = append(res, kv)
        }
        return
}
func reduceF(key string, values []string) string {
        sum := 0
        for _, n := range values {
                i,_ := strconv.Atoi(n)
                sum += i // 所有values相加
        }
        return strconv.Itoa(sum)
}
#+END_SRC
  倒排索引的实现:Map将输入的contents分解成单词,单词作为key,
  文件名作为value.Reduce则统计values中不重复的文件,并将结果字符串化.

[1] [[https://pdos.csail.mit.edu/6.824/papers/gfs.pdf][The Google File System]]
[2] [[https://pdos.csail.mit.edu/6.824/papers/mapreduce.pdf][MapReduce: Simplified Data Processing on Large Clusters]]
